{
 "metadata": {
  "name": "",
  "signature": "sha256:32f641a7544b8bbc37355f78ad306d6b7761de7012113dd6ce7d7b1b094aa87c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## MNIST\n",
      "Utilizes code from crino module. Run notebook with --pylab switch."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "from theano.tensor.nnet.conv import conv2d as conv\n",
      "from mlp import LogisticRegression as LR\n",
      "import gzip, cPickle\n",
      "import time\n",
      "from osdfutils import crino"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: Quadro K600\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# notebook specific imports\n",
      "import lconvista\n",
      "from osdfutils import misc\n",
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib import cm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# uncomment next two lines if inline plotting should be enabled.\n",
      "%matplotlib inline\n",
      "matplotlib.rcParams['savefig.dpi'] = 144"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################\n",
      "# READ AND FORMAT DATA\n",
      "####################    \n",
      "mnist_f = gzip.open(\"mnist.pkl.gz\",'rb')                              \n",
      "train_set, valid_set, test_set = cPickle.load(mnist_f)                \n",
      "\n",
      "dm = train_set[0].mean(axis=0)\n",
      "\n",
      "data = (train_set[0] - dm).reshape(train_set[0].shape[0],1,28,28)\n",
      "dtrgts = train_set[1]\n",
      "valid = (valid_set[0] - dm).reshape(valid_set[0].shape[0],1,28,28)\n",
      "vtrgts = valid_set[1]\n",
      "test = (test_set[0] - dm).reshape(test_set[0].shape[0],1,28,28)\n",
      "ttrgts = test_set[1]\n",
      "\n",
      "mnist_f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "reload(crino)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "<module 'osdfutils.crino' from 'osdfutils\\crino.pyc'>"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################\n",
      "# SET LEARNING PARAMETERS\n",
      "####################  \n",
      "epochs = 20\n",
      "btsz = 100\n",
      "lr = 1.\n",
      "momentum = 0.9\n",
      "decay = 0.95\n",
      "batches = data.shape[0]/btsz\n",
      "tbatches = test.shape[0]/btsz\n",
      "vbatches = valid.shape[0]/btsz\n",
      "print \"LConvISTA -- Learned Convolutional ISTA\"\n",
      "print \"Epochs\", epochs\n",
      "print \"Batches per epoch\", batches\n",
      "print\n",
      "\n",
      "####################\n",
      "# INITIALIZE ALGORITHM PARAMETERS\n",
      "#################### \n",
      "n_filters = 16\n",
      "filter_size = 5 #filters assumed to be square\n",
      "layers = 2\n",
      "weight_reconstruction = 0.01\n",
      "weight_sparsity = 0.01\n",
      "weight_neglog = 1\n",
      "\n",
      "err_weights = (weight_reconstruction,weight_sparsity,weight_neglog)\n",
      "\n",
      "\n",
      "Dinit = {\"shape\": (n_filters,filter_size,filter_size),\n",
      "         \"variant\": \"normal\", \"std\": 0.5}\n",
      "D = crino.initweight(**Dinit)#np.random.randn(n_filters*s,s)#\n",
      "# normalize atoms (SQUARE patches) to 1\n",
      "D /= np.sqrt(\n",
      "        np.asarray(map(lambda patch: (patch**2).sum(keepdims=True),D))\n",
      "     )\n",
      "# reshape to four dimensions to match nnet.conv.conv2d\n",
      "D = D.reshape(1,n_filters,filter_size,filter_size)\n",
      "\n",
      "theta = 0.001\n",
      "\n",
      "L = 1.\n",
      "\n",
      "zinit_shape = (btsz,n_filters,\n",
      "               data[0,0].shape[0]+filter_size-1,\n",
      "               data[0,0].shape[1]+filter_size-1)\n",
      "Xshape = data[:btsz].shape\n",
      "\n",
      "config = {\"D\": D, \"theta\": theta, \"L\": L, \"Zinit\": zinit_shape,\n",
      "          \"layers\": layers, \"Xshape\": Xshape, \"btsz\": btsz,\n",
      "          \"err_weights\": err_weights}\n",
      "\n",
      "# normalize weights according to this config\n",
      "norm_dic = {\"D\": {\"axis\":1, \"c\": 1.}}\n",
      "# threshold theta should be at least some value\n",
      "thresh_dic = {\"theta\": {\"thresh\": 1e-15}}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LConvISTA -- Learned Convolutional ISTA\n",
        "Epochs 20\n",
        "Batches per epoch 500\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################\n",
      "# BUILDING GRAPH\n",
      "#################### \n",
      "X, y, params, Z, rec, cost, cerror, re, sparsity, neglog = lconvista.classifier(config=config, shrinkage=lconvista.sh)\n",
      "grads = T.grad(cost, params)\n",
      "\n",
      "# training ...\n",
      "settings = {\"lr\": lr, \"momentum\": momentum, \"decay\": decay}\n",
      "# ... with stochastic gradient + momentum\n",
      "#updates = crino.momntm(params, grads, settings)#, **norm_dic)\n",
      "updates = crino.adadelta(params, grads, settings)#, **norm_dic)\n",
      "# ... normalize weights\n",
      "\n",
      "updates[params[0]] = updates[params[0]] / T.sqrt(theano.map(lambda patch: (patch**2).sum(keepdims=True),updates[params[0]][0])[0])\n",
      "\n",
      "# ... make sure threshold is big enough\n",
      "updates = crino.max_updt(params, updates, todo=thresh_dic)\n",
      "\n",
      "train = theano.function([X,y],\n",
      "            (cost, cerror, re, sparsity, neglog) + tuple(params),\n",
      "            updates=updates, allow_input_downcast=True)\n",
      "validate_or_test_model = theano.function([X,y],\n",
      "            cerror, allow_input_downcast=True)\n",
      "print 'Graph built.'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[LConvISTA]\n",
        "[AdaDELTA] lr: 1.0; decay: 0.95"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[MAX_UPDT] theta at least at 1e-15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Graph built."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\\\\srv-file.brml.tum.de\\nthome\\msoelch\\AppData\\Roaming\\Python\\Python27\\site-packages\\theano\\scan_module\\scan_perform_ext.py:85: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
        "  from scan_perform.scan_perform import *\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###############\n",
      "# TRAIN MODEL #\n",
      "###############\n",
      "print '... training'\n",
      "\n",
      "# early-stopping parameters\n",
      "patience = 10000  # look as this many examples regardless\n",
      "patience_increase = 2  # wait this much longer when a new best is\n",
      "                       # found\n",
      "improvement_threshold = 0.995  # a relative improvement of this much is\n",
      "                               # considered significant\n",
      "validation_frequency = min(batches, patience / 2)\n",
      "                              # go through this many\n",
      "                              # minibatche before checking the network\n",
      "                              # on the validation set; in this case we\n",
      "                              # check every epoch\n",
      "\n",
      "best_params = [None] * 5\n",
      "params = [None] * 5\n",
      "best_validation_loss = np.inf\n",
      "best_iter = 0\n",
      "test_score = 0.\n",
      "start_time = time.clock()\n",
      "\n",
      "epoch = 0\n",
      "done_looping = False\n",
      "\n",
      "while (epoch < epochs) and (not done_looping):\n",
      "    start = time.clock()\n",
      "    epoch += 1\n",
      "    for mbi in xrange(batches):\n",
      "        newcost, cerror, re, sparsity, neglog, params[0], params[1], params[2], params[3], params[4] = train(data[mbi*btsz:(mbi+1)*btsz],dtrgts[mbi*btsz:(mbi+1)*btsz])\n",
      "        cost += btsz*newcost\n",
      "        # iteration number\n",
      "        iter = (epoch - 1) * batches + mbi\n",
      "\n",
      "        if (iter + 1) % validation_frequency == 0:\n",
      "            # compute zero-one loss on validation set\n",
      "            validation_losses = [validate_or_test_model(valid[i*btsz:(i+1)*btsz],vtrgts[i*btsz:(i+1)*btsz]) for i in xrange(vbatches)]\n",
      "            this_validation_loss = np.mean(validation_losses)\n",
      "            print re, sparsity, neglog\n",
      "            print('epoch %i, minibatch %i/%i, validation error %f %%' % (epoch, mbi + 1, batches, this_validation_loss * 100.))\n",
      "\n",
      "\n",
      "            if this_validation_loss < best_validation_loss:\n",
      "                #improve patience if loss improvement is good enough\n",
      "                if this_validation_loss < best_validation_loss * improvement_threshold:\n",
      "                    best_params = params\n",
      "                    patience = max(patience, iter * patience_increase)\n",
      "\n",
      "                best_validation_loss = this_validation_loss\n",
      "                best_iter = iter\n",
      "\n",
      "                # test it on the test set\n",
      "                test_losses = [validate_or_test_model(test[i*btsz:(i+1)*btsz],ttrgts[i*btsz:(i+1)*btsz]) for i in xrange(tbatches)]\n",
      "                test_score = np.mean(test_losses)\n",
      "\n",
      "                print(('     epoch %i, minibatch %i/%i, test error of '\n",
      "                       'best model %f %%') %\n",
      "                      (epoch, mbi + 1, batches,\n",
      "                       test_score * 100.))\n",
      "\n",
      "        if patience <= iter:\n",
      "                done_looping = True\n",
      "                break\n",
      "    end = time.clock()\n",
      "    print \"Elapsed time for last epoch\", end-start, \"seconds\"\n",
      "    \n",
      "params = best_params"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... training\n",
        "0.736723423004"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7.25519514084 0.503984630108\n",
        "epoch 1, minibatch 500/500, validation error 10.210000 %\n",
        "     epoch 1, minibatch 500/500, test error of best model 10.860000 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed time for last epoch 107.318002592 seconds\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-8-4cfa8547517c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmbi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mnewcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcerror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparsity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneglog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmbi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbtsz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmbi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbtsz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtrgts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmbi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbtsz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmbi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbtsz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mcost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbtsz\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnewcost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# iteration number\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m\\\\srv-file.brml.tum.de\\nthome\\msoelch\\AppData\\Roaming\\Python\\Python27\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m\\\\srv-file.brml.tum.de\\nthome\\msoelch\\AppData\\Roaming\\Python\\Python27\\site-packages\\theano\\scan_module\\scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 656\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    657\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m\\\\srv-file.brml.tum.de\\nthome\\msoelch\\AppData\\Roaming\\Python\\Python27\\site-packages\\theano\\scan_module\\scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    632\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_mit_mot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_mit_sot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_sit_sot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_nit_sot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "D = np.asarray(params[0])\n",
      "im = np.array(misc.visualize(D, 5*5))\n",
      "plt.imshow(im, cmap=cm.gray)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print valid.shape\n",
      "print valid[:14*14].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# show me the money\n",
      "reconstructor = theano.function([X], rec, allow_input_downcast=True)\n",
      "recs = reconstructor(valid[100:200]) + dm.reshape(1,1,28,28)\n",
      "im = np.array(misc.visualize(recs, 28*28))\n",
      "plt.imshow(im, cmap=cm.gray)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "# visualize latents as sparse 2d images\n",
      "reconstructor = theano.function([X], Z, allow_input_downcast=True)\n",
      "recs = reconstructor(valid[:100])\n",
      "im = np.array(misc.visualize(recs, 16*32*32))\n",
      "plt.imshow(im, cmap=cm.gray)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# if sparse code size is not a square number, use matshow\n",
      "plt.matshow(recs)\n",
      "# for gray values\n",
      "# plt.matshow(recs, cmap=cm.gray)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}